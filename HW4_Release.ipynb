{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "celltoolbar": "Create Assignment",
    "colab": {
      "name": "HW4-Release.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dkq9oiyfPQEr",
        "nbgrader": {
          "grade": false,
          "grade_id": "title",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "# CIS 545 Homework 4: Amazon Review Analysis and Classification\n",
        "\n",
        "Your main training set for this assignment is the text from 100,000 reviews from Amazon.com, their timestamps, and their star ratings. The high level goal of this homework is to use the textual and temporal data to predict the star ratings.\n",
        "\n",
        "**Adventurers beware!** Analyzing this data in `sklearn` will likely kill your kernel because it may need to store 1.9 billion values. So instead we will use the package [gensim](https://radimrehurek.com/gensim/) for analysis. gensim specializes in efficient implementations of common modeling techniques for big text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nB-65mi_PQEu",
        "colab": {}
      },
      "source": [
        "# install stuff\n",
        "%%capture\n",
        "!pip install -U gensim\n",
        "!pip install urllib2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3X5NKsi2Bwrh",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-0-0",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Make sure the following line prints the up-to-date version of `gensim`, which at time of releasing this homework was version 3.8.1. If not, run the cell above again. If you don't do this, you may get different answers than us or have annoying error messages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XCZ2LpmRcSIX",
        "colab": {}
      },
      "source": [
        "# check gensim version\n",
        "import gensim\n",
        "gensim.__version__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ngg1pmoZPQE4",
        "colab": {}
      },
      "source": [
        "# import stuff\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "from gensim import corpora\n",
        "from gensim.models import LsiModel, KeyedVectors\n",
        "from gensim.models.tfidfmodel import TfidfModel\n",
        "from gensim.models.nmf import Nmf\n",
        "\n",
        "import sklearn.model_selection as ms\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "from datetime import *\n",
        "from operator import itemgetter\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79R84xo4FESL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!wget https://cis.upenn.edu/~cis545/data/reviews.dict\n",
        "!wget https://cis.upenn.edu/~cis545/data/train_reviews.mm\n",
        "!wget https://cis.upenn.edu/~cis545/data/train_times.npy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vBLPPKcePQE9",
        "colab": {}
      },
      "source": [
        "reviews_dict = corpora.Dictionary.load(\"reviews.dict\")\n",
        "reviews_bow = corpora.MmCorpus('train_reviews.mm')\n",
        "reviews_times  = np.load('train_times.npy')\n",
        "reviews_times.shape = (len(reviews_bow),1)\n",
        "y = np.vstack((np.repeat(1, 4000), np.repeat(2, 4000), np.repeat(3, 4000), np.repeat(4, 4000), np.repeat(5, 4000)))\n",
        "y = np.repeat(y, 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKS2M3lcG2K1",
        "colab_type": "text"
      },
      "source": [
        "## Autograder Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "199wVVxjGznk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: Enter your 8-digit Penn Id as an integer \n",
        "\n",
        "STUDENT_PENN_ID = # TODO #\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aojfs3k4G5ph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import urllib.request\n",
        "import dill\n",
        "import base64\n",
        "\n",
        "api_endpoint = 'https://qvms14rjk2.execute-api.us-east-2.amazonaws.com/default/GallantGrader_v2'\n",
        "\n",
        "class TheGallantGrader: \n",
        "    def __init__(self, student_id, api_endpoint = api_endpoint, homework_id = '4'):\n",
        "        if student_id == None:\n",
        "            print('Error Autograder Not Setup: Enter your 8 digit PennID in the cell above.') \n",
        "        self.student_id   = str(student_id)\n",
        "        self.api_endpoint = api_endpoint\n",
        "        self.homework_id  = homework_id \n",
        "        \n",
        "    def grade(self, question_id, answer):\n",
        "        payload = {'student_id'   : self.student_id,\n",
        "                   'homework_id'  : self.homework_id,\n",
        "                   'test_case_id' : question_id,\n",
        "                   'answer'       : self.serialize(answer)}\n",
        "        params = json.dumps(payload).encode('utf-8')\n",
        "        request = urllib.request.Request(self.api_endpoint, \n",
        "                                         data    = params, \n",
        "                                         headers = {'content-type': 'application/json'})\n",
        "        try:\n",
        "            response = urllib.request.urlopen(request)\n",
        "            response_body = response.read().decode('utf-8')\n",
        "            print('{}'.format(response_body))\n",
        "        except:\n",
        "            print('Error: Grading request could not be completed.')\n",
        "\n",
        "    def serialize(self, obj):\n",
        "        byte_serialized = dill.dumps(obj)\n",
        "        return base64.b64encode(byte_serialized).decode(\"utf-8\")\n",
        "\n",
        "    def deserialize(self, obj):\n",
        "        byte_decoded = base64.b64decode(obj)\n",
        "        return dill.loads(byte_decoded)\n",
        "\n",
        "grader = TheGallantGrader(student_id = STUDENT_PENN_ID, homework_id = '4') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "t0P6-gVuPQFE",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-0",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "## Step 0: Explore the format\n",
        "\n",
        "We will start with exploring the format of all of the data files that we imported above. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5gkoN7m7XvZ0",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-0-1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Step 0.1: gensim dictionary (lexicon)\n",
        "\n",
        "Most data science over text has some form of vocabulary. Simply put, you need to decide which words your model will care about. Very rare words, misspellings, numbers, and urls are good candidates for exclusion, especially since if the model needs any form of normalization, the time complexity of such computations is at least linear in the size of the vocabulary, if not worse.\n",
        "\n",
        "A lexicon associates each word in the vocabulary with an index. Since words are repeated, the model can save space by using the index for every repetition and only linking the index with the string form once. A `gensim` dictionary is special in that it is very fast and allows bidirectional lookups, namely, word to index and index to word.\n",
        "\n",
        "After reviewing the [documentation](https://radimrehurek.com/gensim/corpora/dictionary.html), rewrite the right hand side of each line in the cell below with the answers to these questions.\n",
        "\n",
        "1. In the `gensim` dictionary `reviews_dict`, what is the index of \"best\"? Look it up and store it in a variable named `best`. To clarify, if you find that 42 is the index of \"best\", change the line below so that it sets `best` equal to 42. Of course, you can do this with `best = 42` and earn full points, but it is a litte better to reuse the command with which you found the index. For example, if the `gensim` dictionary worked like a list of strings, you could do it with  \n",
        "`best = reviews_dict.iloc('best')`.\n",
        "2. What word belongs to index 1911? Look it up and store it in a variable named `onenineoneone`.\n",
        "3. What happens when you evaluate `reviews_dict[i]` for some variable `i`? If this returns the word associated with that index, set `idx2word` to `True`. Otherwise, set it to `False`. For example, if `reviews_dict['best']` equals `best`, `idx2word` should be `False`, but if `reviews_dict[1911]` equals `onenineoneone`, `idx2word` should be `True`.\n",
        "\n",
        "Hint: `token2id('best')` and `id2token(1911)` didn't work for me either. Keep trying!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JgQ1DMnnPQFI",
        "nbgrader": {
          "grade": false,
          "grade_id": "answer-0-1",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "colab": {}
      },
      "source": [
        "# answer 0.1\n",
        "best = # TODO #\n",
        "onenineoneone = # TODO #\n",
        "idx2word = # TODO #"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pz5ndlKlHZRp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## AUTOGRADER Step 0.1: Run this to get your score. ##\n",
        "\n",
        "grader.grade(question_id = \"0.1\", answer = (best, onenineoneone, idx2word) )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pAVMO7GZPQFp",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-0-2",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "### Step 0.2: Look up individual reviews\n",
        "\n",
        "`gensim` represents everything in a **sparse** way. Namely, the representation of a review will be a variable-size list that contains counts of the words that _are present_ in the review. A **dense** representation, on the other hand, such as a matrix, would, in addition to the present words, contain zero counts for all of the words that are not in that particular review. For some examples, see [this tutorial](https://radimrehurek.com/gensim/auto_examples/core/run_core_concepts.html).\n",
        "\n",
        "But the optimizations don't stop there! `gensim` also saves space by not directly storing where one document ends and another begins. Such an implementation decision encourages users to stream the dataset through the user's pipeline, rather than attempt to read large chunks into memory. Put another way, you can iterate through the dataset using a loop or vectorized function, but you cannot index. In code:\n",
        "\n",
        "`for doc in corpus` works!\n",
        "\n",
        "`corpus[1911]` does not work!\n",
        "\n",
        "On some occasions, though, it would be convenient for us to, say, look up the 1911th document directly.\n",
        "\n",
        "So let's implement a function that iterates through the `gensim` `corpus`, collects every document whose index appears in `indices`, and returns that list of documents (subset of the dataset). For example, say we want the documents with the following indices: `indices = [0, 19, 11, 0]`. Then `lookup_docs` should return the 1st, 12th, and 20th documents, in that order.\n",
        "\n",
        "To emphasize, if an index appears multiple times in `indices`, just return one copy. And for consistency with our autograder, please return the documents in order of increasing index. That would be be like `corpus[0]`, then `corpus[11]`, then `corpus[19]` in our example. Of course, that way to reference them doesn't work, though!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-s5GeN5SKq2o",
        "nbgrader": {
          "grade": false,
          "grade_id": "answer-0-2",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# answer 0.2 \n",
        "# TODO: Complete the function\n",
        "def lookup_docs(corpus, indices):\n",
        "    # TODO #"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Nj5S7Kyy3yf8",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-0-2-1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Once you have written `lookup_docs`, you may run the cell below (no modification needed) to see how documents are represented in a gensim [corpus](https://radimrehurek.com/gensim/corpora/mmcorpus.html). In each review, `gensim` stores a tuple of size 2 for each distinct word in the review. The first number in the tuple is the index of the word in the dictionary and the second number in the tuple is the count of the times that word appeared in that review."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3diZMuUOPQFx",
        "nbgrader": {
          "grade": true,
          "grade_id": "visible-test-0-2",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "indices = [10,18]\n",
        "docs = lookup_docs(reviews_bow, indices)\n",
        "\n",
        "print(docs[0])\n",
        "print(docs[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bjl67ZWq4tZm",
        "nbgrader": {
          "grade": true,
          "grade_id": "hidden-test-0-2",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "## AUTOGRADER Step 0.2: Run this to get your score. ##\n",
        "\n",
        "grader.grade(question_id = \"0.2\", answer = docs)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gn0lzmyPaP5j",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-0-3",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Step 0.3: Make reviews more human-readable\n",
        "\n",
        "Now, we would like you to write a function that takes a `gensim` bag of words document and its corresponding dictionary as input and returns a \"translated\" version that is more readable. The reviews are already represented as bags of words, so recall that you cannot recover the order of the words in the reviews. But, we would like you to spell out the repeats of each word. So, if the original review were \"to be or not to be\", `reviews_bow` would have something like:\n",
        "\n",
        "`[(0, 2.0), (1, 1.0), (2, 1.0), (3, 2.0)]`\n",
        "\n",
        "and we would like you to return the string\n",
        "\n",
        "`\"be be not or to to\"`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H-XXZOTtaiAM",
        "nbgrader": {
          "grade": false,
          "grade_id": "answer-0-3",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# answer 0.3\n",
        "# TODO: Complete the function\n",
        "def translate_review(review, reviews_dict):\n",
        "    # TODO #\n",
        "\n",
        "readable_1 = translate_review(docs[0], reviews_dict)\n",
        "print(readable_1)\n",
        "\n",
        "readable_2 = translate_review(docs[1], reviews_dict)\n",
        "print(readable_2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCs7pGm_JPvM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## AUTOGRADER Step 0.3: Run this to get your score. ##\n",
        "\n",
        "grader.grade(question_id = \"0.3\", answer =  (translate_review, dict(reviews_dict)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-BJG91UHPQG6",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-0-4",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "### Step 0.4: Parse review times\n",
        "\n",
        "It might be useful in predicting the scores of the reviews to know when the reviews were written. In this dataset, the day of the review was recorded as the number of seconds that passed between midnight on January 1, 1970 (the beginning of time for many computer systems) and the time the review was created. This may be efficient because it is one integer, but it is not very convenient. So we are going to convert these int objects to [datetime](https://docs.python.org/3/library/datetime.html) objects:\n",
        "\n",
        "**Do not change `review_times` in any way. Work with other variables instead.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pjYIR8V960Hb",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-0-4-1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "#### Step 0.4.1: Convert times vector\n",
        "\n",
        "The `convert_times` function should take in the entire `review_times` vector at once. It should return a new pandas `Series` object made from `review_times` but the entries should be of type `datetime` or `Timestamp`.\n",
        "\n",
        "Hint: You might find `datetime.fromtimestamp` to be useful."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2AvvxOpjPQG9",
        "nbgrader": {
          "grade": false,
          "grade_id": "answer-0-4-1",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "colab": {}
      },
      "source": [
        "# answer 0.4.1\n",
        "# TODO: Complete the function\n",
        "def convert_times(reviews_times):\n",
        "    # TODO #"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJuU3--pKap5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "converted_times = convert_times(reviews_times)\n",
        "print(\"converted_times is a\", type(converted_times))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBVsOFvFKTYW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## AUTOGRADER Step 0.4: Run this to get your score. ##\n",
        "\n",
        "grader.grade(question_id = \"0.4\", answer = (str(type(converted_times)), str(type(converted_times[0])), str(type(converted_times[1])), str(converted_times[1])))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fyKf4Ryt7O6H",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-0-4-2",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "#### Step 0.4.2: Time math\n",
        "\n",
        "The `days_before` function should take in one time value (after applying `convert_times`) and return a new time value that is exactly `offset` days before the input.\n",
        "\n",
        "Hint: You might find `timedelta` to be useful."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eYEkmo2d6NQn",
        "nbgrader": {
          "grade": false,
          "grade_id": "answer-0-4-2",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# answer 0.4.2\n",
        "# TODO: Complete the function\n",
        "def days_before(time_item, offset):\n",
        "    # TODO #"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7tJgAcauPQH1",
        "nbgrader": {
          "grade": true,
          "grade_id": "visible-test-0-4-2",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false
        },
        "colab": {}
      },
      "source": [
        "display(converted_times[0])\n",
        "forty_days_before_review_times_0 = days_before(converted_times[0], 40)\n",
        "display(forty_days_before_review_times_0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89ckXfd7LCkw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## AUTOGRADER Step 0.4.2: Run this to get your score. ##\n",
        "\n",
        "grader.grade(question_id = \"0.4.2\", answer = str(forty_days_before_review_times_0))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tywL0VjAbYMY",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-1",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "## Step 1: How many components?\n",
        "\n",
        "We will need to perform dimesionality reduction on our dataset before we can proceed further with the supervised task of predicting the star ratings. One of the greatest benefits of gensim is that it can decompose a sparse dataset directly. Indeed, they post some impressive numbers about their SVD speed [here](https://radimrehurek.com/gensim/models/lsimodel.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "u3W2ZOv0nlrE",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-1-1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Step 1.1: PCA on raw counts\n",
        "\n",
        "We are first going to choose too many components deliberately, just to make sure that we see the whole picture. But note that 1000 components would still require us to store 100 million numbers. So that is probably too big for convenient exploration of the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sxXINIEFABa6",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-1-1-1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "#### Step 1.1.1: Train the PCA model\n",
        "\n",
        "Train a gensim `LsiModel` on `reviews_bow` using `reviews_dict` as the dictionary and 1000 components. This magic number is provided as `max_cutoff`. The API is [here](https://radimrehurek.com/gensim/models/lsimodel.html).\n",
        "\n",
        "**This step took about 4 minutes for my Colab instance to complete.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rDRc0IRfbYMe",
        "nbgrader": {
          "grade": false,
          "grade_id": "answer-1-1-1",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "colab": {}
      },
      "source": [
        "# answer 1.1.1\n",
        "# TODO: Learn the syntax of the LsiModel command\n",
        "max_cutoff = 1000\n",
        "# TODO #"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6Skq9LPDbYMn",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-1-1-2",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "#### Step 1.1.2: Extract the singular values\n",
        "\n",
        "Look at the [API page](https://radimrehurek.com/gensim/models/lsimodel.html) to figure out how to get the singular values from a trained model. Feed those and `max_cutoff` to the `plot_variance_vs_components` function, which you do not have to edit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pfDFbW_qbYMq",
        "colab": {}
      },
      "source": [
        "def plot_variance_vs_components(singular_values, cutoff):\n",
        "    evr = np.array([singular_values[i]**2 / sum(singular_values**2) for i in range(cutoff)])\n",
        "    var = np.cumsum(evr*100)\n",
        "    plt.ylabel('% Variance Explained')\n",
        "    plt.xlabel('# of Components')\n",
        "    plt.title('PCA Analysis')\n",
        "    plt.style.context('seaborn-whitegrid')\n",
        "    plt.plot(var)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HQHACc0ow6K5",
        "nbgrader": {
          "grade": false,
          "grade_id": "answer-1-1-2",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# answer 1.1.2\n",
        "# TODO: Plot variance versus number of components\n",
        "# TODO #"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WLgVssiNbYMy",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-1-1-2-1",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "The good news is this curve is very steep in the beginning, which shows that a lot of information is conveyed in the first components. However, there is no plateau that we can use to choose a cutoff!\n",
        "\n",
        "**So, let's go back to the dataset. Are the numbers in `reviews_bow` distributed sensibly?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FqZ4vnCPn6O-",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-1-2",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Step 1.2: TF-IDF -- a better distribution\n",
        "\n",
        "The function below allows us to visualize the distribution of the values in the bag of words. You do not need to edit it. Recall that there are no zero values by nature of the sparse representation. The function has two convenient features:\n",
        "\n",
        "1. It allows you to transform the values uniformly using an optional second argument.\n",
        "2. By subtracting the mean, the new mean will line up with $x=0$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "li80IItWzgsK",
        "colab": {}
      },
      "source": [
        "def plot_values(reviews, function=None):\n",
        "    values = []\n",
        "    for doc in reviews:\n",
        "        for (word, score) in doc:\n",
        "            if not function: values.append(score)\n",
        "            else:            values.append(function(score))\n",
        "\n",
        "    plt.hist(values - np.mean(values), bins='auto')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sJRiDUPBfAiK",
        "colab": {}
      },
      "source": [
        "plot_values(reviews_bow)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "t8fdmx8CfQbY",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-1-2-1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "It appears that our values are very highly skewed. Therefore, minmax and standard scaling would not (yet) be appropriate. Let's see if we can make it look better by log scaling the values:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3W-hAN9ZgMZw",
        "colab": {}
      },
      "source": [
        "plot_values(reviews_bow, np.log)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bF81W6ETiivP",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-1-2-2",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "It is a little better, but only a little bit. Perhaps a double log?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Va1byrsCg-pa",
        "colab": {}
      },
      "source": [
        "plot_values(reviews_bow, lambda x: np.log(np.log(x+1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xKpC3bnGg4Yo",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-1-2-3",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Still not so good. There are (at least) two outstanding issues with this distribution:\n",
        "\n",
        "1. The vast majority of words only occur once per review.\n",
        "2. In the rare case that a word occurs more than once, we can't tell if that is because it is especially important or because it is a common word, like a stop word.\n",
        "\n",
        "Therefore, we are going to convert our counts into [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) scores. Luckily, this is built in to `gensim` so this can be done in a couple lines of code. The API is [here](https://radimrehurek.com/gensim/models/tfidfmodel.html). Complete the function below that converts the data to TF-IDF scores. Note: that is a two step process. First, you need to initialize and fit a TF-IDF model to `reviews_bow`. (use default values for all hyperparameters **EXCEPT you should set `normalize=True`**). Then, you should apply your TF-IDF model to `reviews_bow` to transform it. Return the new version of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dhlmCiiTzgph",
        "nbgrader": {
          "grade": false,
          "grade_id": "answer-1-2",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# answer 1.2\n",
        "# TODO: Complete the function\n",
        "def make_tfidf(reviews_bow):\n",
        "    # TODO #"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vFNBR3JTZDYs",
        "nbgrader": {
          "grade": true,
          "grade_id": "visible-test-1-2",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "reviews_tfidf = make_tfidf(reviews_bow)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kN1R8-annaHN",
        "colab": {}
      },
      "source": [
        "plot_values(reviews_tfidf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgRik0wfn8wz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## AUTOGRADER Step 1.2: Run this to get your score. ##\n",
        "\n",
        "grader.grade(question_id = \"1.2\", answer = str(type(reviews_tfidf)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4XxMZv1Skwkn",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-1-2-4",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "This should look a lot better. Log scaling it may make the distribution look a bit more symmetrical, but this would come at the cost of collapsing some distinctions in the right tail, so we will not do it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wADH4r2VoIQE",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-1-3",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Step 1.3: PCA on TF-IDF scores\n",
        "\n",
        "Let's try the PCA again and plot a new variance versus number of components."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eunxl15fzg0U",
        "nbgrader": {
          "grade": false,
          "grade_id": "answer-1-3",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# answer 1.3\n",
        "# TODO: Train an LsiModel and run the plot_variance_vs_components function\n",
        "# TODO #"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Vrhnv0Qh5RVQ",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-1-3-1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "If anything, this graph is less helpful than before. **So, instead, we would like to use downstream performance of the classifier to tune this hyperparameter.** So let's build the remaining pieces that we need."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0ErKk3gaPQIR",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-2",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "## Step 2: Interface with sparse representations\n",
        "\n",
        "To get the real benefit of dimensionality reduction, it is important to consider which pieces of the decomposition are actually needed. Then, we can simply throw away the rest. To help you become familiar with the different pieces we will fully decompose and reconstruct the toy dataset of 5 computer science and 4 math article titles using `gensim`. It will be important later on that you only apply the functions that you write in this section to the pieces that you need on the big dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0hhoUvIZpr4d",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-2-0",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Step 2.0: The sparse toy dataset\n",
        "\n",
        "After lower casing, tokenizing, and stop wording, the corpus looks like `titles` in the cell below. Then, we create a dictionary and a sparse document-term matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XUluV0evPQIU",
        "colab": {}
      },
      "source": [
        "titles = [['human', 'interface', 'computer'],\n",
        "          ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
        "          ['eps', 'user', 'interface', 'system'],\n",
        "          ['system', 'human', 'system', 'eps'],\n",
        "          ['user', 'response', 'time'],\n",
        "          ['trees'],\n",
        "          ['graph', 'trees'],\n",
        "          ['graph', 'minors', 'trees'],\n",
        "          ['graph', 'minors', 'survey']]\n",
        "\n",
        "titles_dict = corpora.Dictionary(titles)\n",
        "titles_bow = [titles_dict.doc2bow(title) for title in titles]\n",
        "display(titles_bow)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gCJTCgU0PQIc",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-2-1",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "### Step 2.1: Sparse to dense\n",
        "\n",
        "To get the term-document matrix that we have seen in lecture, we need to convert this matrix to its dense form. Write a function `densify` that takes as input:\n",
        "\n",
        "1. a sparse matrix in the format of `titles_bow` above\n",
        "3. an integer number of columns\n",
        "\n",
        "and returns a NumPy array. Note that `titles_bow` is a document-term matrix, not a term-document matrix, so we transpose it in the test cell to show the matrix from lecture (with the rows and columns slightly reordered).\n",
        "\n",
        "You may not use the `corpus2dense` function from `gensim`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iuzFAAekPQId",
        "nbgrader": {
          "grade": false,
          "grade_id": "answer-2-1",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "colab": {}
      },
      "source": [
        "# answer 2.1\n",
        "# TODO: Complete the function\n",
        "def densify(sparse, columns):\n",
        "    # TODO #"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0PvkEMcyPQIi",
        "nbgrader": {
          "grade": true,
          "grade_id": "visible-test-2-1-1",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false
        },
        "colab": {}
      },
      "source": [
        "td = densify(titles_bow, len(titles_dict)).transpose()\n",
        "print(td)\n",
        "print(td.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1kR4wHdMX_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## AUTOGRADER Step 2.1: Run this to get your score. ##\n",
        "\n",
        "grader.grade(question_id = \"2.1\", answer = (td[4].tolist(), round(sum(sum(td))).item(), str(type(td))))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O5axMVwhPQN6",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-2-2",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "### Step 2.2: Toy PCA reconstruction\n",
        "\n",
        "In the cell below, write a function called `reconstruction` that takes as input:\n",
        "\n",
        "1. a sparse matrix\n",
        "2. a gensim dictionary\n",
        "2. a cutoff for PCA\n",
        "\n",
        "The function should compute an `LsiModel` and reconstruct the original matrix. \n",
        "\n",
        "**There is something unexpected about the correct solution to this part!**\n",
        "\n",
        "Before turning to Piazza, print the dimensions of the pieces that you are working with, using `.shape`. What are the dimensions of the original? What are the dimensions of the outputs from `LsiModel`? How can you multiply the pieces together to get a match? You can do this! We have faith in you!\n",
        "\n",
        "Note that there could be a loss because the function only computes the part of the singular value decomposition that is needed according to `cutoff`. So after reconstructing, let's quantify the loss: compute the difference between the reconstructed matrix and the original. Then, take the Frobenius norm of that difference matrix. Divide by the Frobenius norm of the original. Make this the return value for the function.\n",
        "\n",
        "Hint: The right singular vectors ($V$ or `model[sparse]`) already contain the singular values ($S$ or `model.projection.s`) so don't include them again!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UtJAyg6SPQN8",
        "nbgrader": {
          "grade": false,
          "grade_id": "answer-2-2",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "colab": {}
      },
      "source": [
        "# answer 2.2\n",
        "# TODO: Complete the function\n",
        "def PCA_reconstruction(sparse, gsdict, cutoff):\n",
        "    # TODO #"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Nn70AE0JPQOO",
        "nbgrader": {
          "grade": true,
          "grade_id": "visible-test-2-2",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false
        },
        "colab": {}
      },
      "source": [
        "for cutoff in range(2,10):\n",
        "    error = PCA_reconstruction(titles_bow, titles_dict, cutoff)\n",
        "    print(\"The reconstruction error with\", cutoff, \"components on the the toy dataset is\", error)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCuuw47PMSMG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## AUTOGRADER Step 2.2: Run this to get your score. ##\n",
        "\n",
        "answer1 = PCA_reconstruction(titles_bow, titles_dict, 2)\n",
        "answer2 = PCA_reconstruction(titles_bow, titles_dict, 6)\n",
        "grader.grade(question_id = \"2.2\", answer = (answer1.item(), answer2.item()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5Rn49PaMlY-M",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-3",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "## Step 3: Choose the number of components via the downstream task\n",
        "\n",
        "Using classification performance to choose the number of components is arguably even better than the plateau method, because we are optimizing directly on the downstream task rather than something intrinsic to the dataset. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qAbvT5iqrCI8",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-3-1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Step 3.1 Train the random forest\n",
        "\n",
        "The code below:\n",
        "\n",
        "1. combines the review TF-IDF scores and the date information into one dataset\n",
        "2. splits off 20% of the training data as a validation set\n",
        "3. Initializes a random forest with 70 estimators\n",
        "\n",
        "To finish the pipeline, add the code that trains the [random forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) and computes the accuracy on the test set. Return that number as a real value between 0 and 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "acWFX8EsrCdM",
        "nbgrader": {
          "grade": false,
          "grade_id": "answer-3-1",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# answer 3.1\n",
        "# TODO: Complete the function\n",
        "def evaluate_model(X, review_times, y):\n",
        "    X = np.hstack((X, review_times))\n",
        "    X_train, X_test, y_train, y_test = ms.train_test_split(X, y, test_size=0.2, random_state = 1911)\n",
        "    rfor = RandomForestClassifier(n_estimators=70, random_state=1911)\n",
        "    # TODO #"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XIy40pHYrClZ",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-3-2",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Step 3.2 Compare performance\n",
        "\n",
        "In the cell below, finish the `evaluate_cutoffs` function. The missing code should train an `LsiModel`, compute the $V$ matrix (right singular vectors), call `densify` on that, and pass the dense matrix to evaluate model. Store all of your accuracies in a list named `results`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VsfJ3KIglY-S",
        "nbgrader": {
          "grade": false,
          "grade_id": "answer-3-2",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "colab": {}
      },
      "source": [
        "# answer 3.2\n",
        "# TODO: Complete the function\n",
        "def evaluate_cutoffs(X_orig, X_dict, X_times, y, cutoffs):\n",
        "    results = []\n",
        "    for cutoff in cutoffs:\n",
        "        np.random.seed(1911)\n",
        "    # TODO #"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "n6Wrw13-SXbE",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-3-2-1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "**WARNING: The following cell should take a while to complete.**\n",
        "\n",
        "Each of the 30 models takes a minute or two, and the later ones are bigger (correspondingly slower). Therefore we are going to analyze your output for grading. Once you have a good idea about the best performing model in this set, give us that accuracy and we will check if it is in the expected range."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VDAI7SAWbD1K",
        "colab": {}
      },
      "source": [
        "results = evaluate_cutoffs(reviews_tfidf, reviews_dict, reviews_times, y, range(10,40))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7Gmo6qmvlY-f",
        "nbgrader": {
          "grade": true,
          "grade_id": "visible-test-3-2",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false
        },
        "colab": {}
      },
      "source": [
        "display(results)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FexYM3kGNXdl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## AUTOGRADER Step 3.2: Run this to get your score. ##\n",
        "\n",
        "answer = max(results)\n",
        "grader.grade(question_id = \"3.2\", answer = (len(results), answer.item()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uxvkclGxs_s5",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-4",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## Step 4: k-means clustering\n",
        "\n",
        "So far, we have one system for classifying the number of stars in a review. But maybe there are patterns that are only true for some subsets of the data? To uncover this, we would like to cluster the reviews."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3Aaxrh3KuRZH",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-4-0",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Step 4.0: Which version of the data?\n",
        "\n",
        "Recall that k-means has a runtime complexity with the strongest term proportional to:\n",
        "\n",
        "(# of dimensions)(# of points)(# of clusters)(# of iterations)(# of restarts)\n",
        "\n",
        "Let's focus on the first three terms. The number of points is 100,000, which is pretty large. Therefore, we will have to be especially careful with the number of dimensions and clusters.\n",
        "\n",
        "In the previous steps, we generated dimensionality-reduced versions of the dataset. While they did not capture a large, satisfying percentage of the variance in the reviews, the random forest classifier hinted that relatively few principal components were enough to capture the relevant variance for classifying star ratings. Specifically, my random forest seemed to hit a performance ceiling somewhat before reaching 40 components. Therefore, let's use the TF-IDF version with 40 components.\n",
        "\n",
        "In the cell below, add the code that trains the `LsiModel`, computes the right singular vectors, and densifies these projections. Store this dimensionality-reduced dataset as `X`. What are the expected dimensions?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3xSUnNABs0ux",
        "nbgrader": {
          "grade": false,
          "grade_id": "answer-4-0",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# answer 4.0\n",
        "# TODO: Reduce the dimensions of the dataset\n",
        "cutoff = 40\n",
        "np.random.seed(1911)\n",
        "# TODO #"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NwoSMd8e4inF",
        "nbgrader": {
          "grade": true,
          "grade_id": "visible-test-4-0",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYxq0eSkrNZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## AUTOGRADER Step 4.0: Run this to get your score. ##\n",
        "\n",
        "grader.grade(question_id = \"4.0\", answer = X.shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zGtBAayHyFOP",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-4-1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Step 4.1: Collect SSWs\n",
        "\n",
        "In the cell below, the function called `test_cluster_size` iterates over the numbers of clusters in the array `num_clusters`. The function takes as input (1) the data as a matrix and (2) the `num_clusters` array. \n",
        "\n",
        "Add the missing code that should cluster the data using k-means and store the $SS_W$ values.\n",
        "\n",
        "Note from the `sklearn.cluster` documentation on __[k-means](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)__:\n",
        "\n",
        "Attributes:\t\n",
        "* `cluster_centers_` : array, [n_clusters, n_features]\n",
        " Coordinates of cluster centers\n",
        "\n",
        "* `labels_` :\n",
        "Labels of each point\n",
        "\n",
        "* `inertia_` :\n",
        "Sum of squared distances between data points and their cluster centers\n",
        "\n",
        "Finally, return a list of $SS_W$ values using the attributes above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I4aay58hs0xr",
        "nbgrader": {
          "grade": false,
          "grade_id": "answer-4-1",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# answer 4.1\n",
        "# TODO: Complete the function\n",
        "def test_cluster_size(data, num_clusters):\n",
        "    scores = []\n",
        "    for i in num_clusters:\n",
        "        km = KMeans(n_clusters=i, init='k-means++', n_init=30, max_iter=10, \n",
        "                    tol=1e-4, random_state=1911, n_jobs=1)\n",
        "    # TODO #"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "x1Nn47RSV7iO",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-4-1-1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "The cell below also takes a while to run because it is going to cluster the data 38 times."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Fjk1iQIkZjUz",
        "nbgrader": {
          "grade": true,
          "grade_id": "visible-test-4-1-1",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "num_clusters = range(2, 40)\n",
        "ssws41 = test_cluster_size(X, num_clusters)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mM73T_791b5F",
        "nbgrader": {
          "grade": true,
          "grade_id": "visible-test-4-1-2",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "display(ssws41)\n",
        "if (len(ssws41) != 38):\n",
        "    raise ValueError(\"Did not compute SSWs for the given values of k.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6ZNeae8N0vK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## AUTOGRADER Step 4.1: Run this to get your score. ##\n",
        "\n",
        "grader.grade(question_id = \"4.1\", answer = [item.item() for item in ssws41] )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kF4dj3Jc0yx5",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-4-2",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Step 4.2: Find the elbow?\n",
        "\n",
        "The following provided code helps you plot the number of clusters (from 2 to 40) versus $SS_W$. You do not need to modify these two cells.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8Xu7aLb1s00U",
        "colab": {}
      },
      "source": [
        "def plot_clusters(num_clusters, distortions):\n",
        "    plt.figure()\n",
        "    plt.xlabel('Number of Clusters')\n",
        "    plt.ylabel('Distortion')\n",
        "    plt.title('Cluster Analysis')\n",
        "    plt.style.context('seaborn-whitegrid')\n",
        "    plt.plot(num_clusters, distortions)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5jjS_CQzXUQY",
        "colab": {}
      },
      "source": [
        "plot_clusters(num_clusters, ssws41)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CZonCmMEWvbH"
      },
      "source": [
        "Do you see a clear \"elbow\" in this graph??\n",
        "\n",
        "Probably not.\n",
        "\n",
        "Just so we can test your solution, we will mathematically define elbow as:\n",
        "\n",
        "$$\\hat{k}_{SSW} = \\underset{k}{\\operatorname{argmin}} (SS_W(k) - SS_W(k+1))$$\n",
        "\n",
        "This is not a perfect mathematical definition because it does not take into account how much $SS_W$ dropped before the selected point. But for this dataset, it does provide one consistent answer.\n",
        "\n",
        "In the cell below, complete the function that implements this mathematical definition. Note that we only pass in the list of distortion values. \n",
        "\n",
        "**So the function should return the index of the selected number of clusters!!**\n",
        "\n",
        "Look at the visible test for this subsection to see how we ultimately assign the value of $k$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lyWFRaX8W1OB",
        "nbgrader": {
          "grade": false,
          "grade_id": "answer-4-2",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# answer 4.2\n",
        "# TODO: Complete the function\n",
        "def sharpest(distortions):\n",
        "    # TODO #"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NodsP9TEXnBm",
        "nbgrader": {
          "grade": true,
          "grade_id": "visible-test-4-2",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "khat42 = num_clusters[sharpest(ssws41)]\n",
        "print(\"I have chosen to have\", khat42, \"clusters.\")\n",
        "if ((khat42 < 2) or (khat42 > 39)):\n",
        "    raise ValueError('k hat is not in the right range')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LytpCo6OXU7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## AUTOGRADER Step 4.2: Run this to get your score. ##\n",
        "\n",
        "grader.grade(question_id = \"4.2\", answer = khat42)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RkZhBXB12L0e",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-4-3",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Step 4.3: The Variance Ratio Criterion\n",
        "\n",
        "Perhaps we can shift to a different cluster evaluation metric that gives a more satisfying suggestion for the number of clusters.\n",
        "\n",
        "Recall the Variance Ratio Criterion ($VRC$), given by\n",
        "\n",
        "$$ VRC(k) = \\frac{SS_B}{k-1} / \\frac{SS_W}{N - k}$$\n",
        "\n",
        "where $SS_B$ is the sum of squared distance between the cluster centers and the grand mean (calculated per data point), $k$ is the number of clusters, $SS_W$ is the sum of squared distance between data points and their assigned cluster centers, and $N$ is the number of data points."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IHvHvApo2vT7",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-4-3-0",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "#### Step 4.3.0: The grand mean\n",
        "\n",
        "Before we apply the full formula, please compute the grand mean of the dataset. What does this represent?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NNY-f2PT2v7w",
        "nbgrader": {
          "grade": false,
          "grade_id": "answer-4-3-0",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# answer 4.3.0\n",
        "# TODO: Compute grand_mean\n",
        "# TODO #"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9QZjpw-paikZ",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-4-3-1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "#### Step 4.3.1: Interpret the grand mean\n",
        "\n",
        "The grand mean is the text of the \"average\" review on Amazon. Let's figure out what that is a bit more precisely for this dataset. The function below finds real data points, i.e. real reviews, that are the closest neighbors to a given vector (`item`). `X_proj` is the dataset, `mask` is a list of booleans stating whether each item in the dataset is an eligible neighbor (we need this later), and `k` is the number of neighbors we would like to find. Write the missing code which should:\n",
        "\n",
        "1. Normalize `item` by its Frobenius norm.\n",
        "2. Loop through the dataset. Exclude the items that have a corresponding `False` value in `mask`.\n",
        "3. For each eligible item in the dataset, compute the [cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity) with `item`. Remember that you have normalized `item` but you will still need to normalize the other vector. \n",
        "4. Store the cosines in a list. It may be useful to put the cosines in tuples with the corresponding indices, but you don't have to do it this way.\n",
        "5. Find the `k` highest cosine values.\n",
        "6. Return the indices corresponding to these highest cosines. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cD_pwHiqa5HY",
        "nbgrader": {
          "grade": false,
          "grade_id": "answer-4-3-1",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# answer 4.3.1\n",
        "# TODO: Complete the function\n",
        "def k_nearest_neighbors(X_proj, mask, item, k):\n",
        "    # TODO #"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QXP0EqlucnN3",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-4-3-1-1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "This visible test prints the \"readable\" versions of the ten nearest neighbors to the grand mean review using `translate_review` from Step 0.2. Do you agree that these are acceptable \"average\" reviews?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nQ_JXEwJ2wFm",
        "nbgrader": {
          "grade": true,
          "grade_id": "visible-test-4-3-1",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "most_typical_indices = k_nearest_neighbors(X, [True]*len(X), grand_mean, 10)\n",
        "most_typical_reviews = lookup_docs(reviews_bow, most_typical_indices)\n",
        "for review in most_typical_reviews:\n",
        "    print(translate_review(review, reviews_dict))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmpzT535Ol-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## AUTOGRADER Step 4.3.1: Run this to get your score. ##\n",
        "\n",
        "grader.grade(question_id = \"4.3.1\", answer = (most_typical_indices, most_typical_reviews))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y6aigeyBZkpj",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-4-3-2",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "#### Step 4.3.2 Implement VRC\n",
        "\n",
        "Complete the function `test_vrc(data, max_num_clusters)` that computes the $VRC$ for each value of k in `num_clusters`. Since we are passing in the data, compute a new grand mean within the function. However, since the grand mean does not depend on the clusters, you should not compute it within a loop. Please compute $SS_B$ using the grand mean, the cluster centers, and the assignments only (no additional libraries or built-in values). Just as a warning, it is expected that your $SS_W$ and $SS_B$ may not add up to exactly the same number every time, but the sum should not change too much.\n",
        "\n",
        "Additionally, please also compute a related ratio: \n",
        "\n",
        "$$\\eta^2 = \\frac{SS_B}{SS_B + SS_W}$$ \n",
        "\n",
        "This $\\eta^2$ (eta squared) is an effect size that pairs with your $VRC$ statistic. Basically all of the $VRC$s are statistically significant because we have so many data points. This is why the effect size is so important. The literature recommends an effect size of at least 0.12.\n",
        "\n",
        "The return statement is given because we would like to keep the $VRC$s and the $\\eta^2$s."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tE7CZrN32wIN",
        "nbgrader": {
          "grade": false,
          "grade_id": "answer-4-3-2",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# answer 4.3.2\n",
        "# TODO: Complete the function\n",
        "def test_vrc(data, num_clusters):\n",
        "    # TODO #\n",
        "    return vrcs, etas_squared"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s_5QvbFOf_7u",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-4-3-2-1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "The code below takes a while to run just as the normal clustering before. I recommend printing the $VRC$ and $\\eta^2$ values as the come, so that you can track the progress."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BRk1XWzN2wKz",
        "nbgrader": {
          "grade": true,
          "grade_id": "visible-test-4-3-2-1",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "num_clusters = range(2,40)\n",
        "vrcs432, etas_squared432 = test_vrc(X, num_clusters)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE1GDpPO1zpN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## AUTOGRADER Step 4.3.2.1: Run this to get your score. ##\n",
        "\n",
        "grader.grade(question_id = \"4.3.2.1\", answer = (vrcs432, etas_squared432))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GBApDsWsJubS",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-4-3-3",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "#### Step 4.3.3: Select a number of clusters with VRC\n",
        "\n",
        "The code below prints rounded versions of the $VRC$s and $\\eta^2$s. Then, it plots the number of clusters (from 2 to 40) versus $VRC$. You do not need to modify this cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6Jqoq2NTXVcs",
        "nbgrader": {
          "grade": true,
          "grade_id": "visible-test-4-3-2-2",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "for i in range(len(num_clusters)):\n",
        "    print(\"%2d\"%num_clusters[i], \n",
        "          \"%d\"%np.round(vrcs432[i], 0), \n",
        "          np.round(etas_squared432[i], 2))\n",
        "\n",
        "plot_clusters(num_clusters, vrcs432)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iiJK2Y3EoeAw",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-4-3-3-1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Much better, right??\n",
        "\n",
        "Complete the `best_vrc` function that compares and chooses a number of clusters based on the $VRC$s and $\\eta^2$s. Note that you are now looking for local maxima, so your elbow method should not be used again. Let's define a maximum as a point where the graph is increasing just before and decreasing just after. Return a list of all indices of `distortions` that are maxima. Then, these can be used to select $k$s from the `num_clusters` array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9iVFopkm2wNj",
        "nbgrader": {
          "grade": false,
          "grade_id": "answer-4-3-3",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# answer 4.3.3\n",
        "# TODO: Complete the function\n",
        "def best_vrc(distortions):\n",
        "    # TODO #"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PSqtwSmRowZG",
        "nbgrader": {
          "grade": true,
          "grade_id": "visible-test-4-3-3",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "khat433 = [num_clusters[i] for i in best_vrc(vrcs432)]\n",
        "print(\"A good number of clusters is one of these:\", khat433)\n",
        "if ((min(khat433) < 2) or (max(khat433) > 39)):\n",
        "    raise ValueError('k hat is not in the right range')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2p7sLR8PFu8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## AUTOGRADER Step 4.3.3: Run this to get your score. ##\n",
        "\n",
        "grader.grade(question_id = \"4.3.3\", answer = khat433)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "016dNhVhiJha",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-5",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## Step 5: t-SNE\n",
        "\n",
        "In this last section, we are going to create a t-SNE plot that may help us decide how to use the clusters that we found in the previous section. More specifically, does k-means find differences between the reviews that are related to the star ratings, or other differences?\n",
        "\n",
        "We are going to use the clustering given below for this section. Double check that `X` is still the same as when you defined it in Step 4.0. You do not need to modify the cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WBQp-W9VC2vT",
        "colab": {}
      },
      "source": [
        "km = KMeans(n_clusters=35, init='k-means++', n_init=30, max_iter=10, \n",
        "            tol=1e-4, random_state=1911, n_jobs=1)\n",
        "km.fit(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "t8EZ-Hcqi_rE",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-5-1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Step 5.1: Exemplars of each cluster\n",
        "\n",
        "Let's begin by approaching this question in a somewhat qualitative way. Namely, let's find the nearest review to each cluster center. Complete the function below that iterates through the cluster centers of `km`. For each cluster center, call `k_nearest_neighbors`. Use the cluster assignments (labels) from `km` to construct the `mask` parameter for `k_nearest_neighbors`. The key idea here is that you want to search only through the reviews that were assigned to that cluster when searching for neighbors. It really should not change your answer, but it is a whole lot faster to do it this way. Alternatively, you could subset the dataset and pass in `[True]*(number_of_points_in_that_cluster)` as the mask, i.e. the mask has all true values, so no item is masked. But keeping track of indices is harder in that case.\n",
        "\n",
        "The function should return a list of lists of indices. There is one list per cluster center. Each index in one of these lists corresponds to a closest neighbor to a cluster center."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sa6Zmne-owe8",
        "nbgrader": {
          "grade": false,
          "grade_id": "answer-5-1",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# answer 5.1\n",
        "# TODO: Complete the function\n",
        "def get_exemplars(X_proj, km, n_exemplars):\n",
        "    # TODO #"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yzs_CAuOnIDn",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-5-1-1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "The visible test cell below finds the indices of the nearest neighbors to each cluster center. Then it looks up the vectors for each of these indices and prints the readable version of each vector. Depending on your implementation this cell could take a long time. You do not need to modify this cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qmCeF6alowiU",
        "nbgrader": {
          "grade": true,
          "grade_id": "visible-test-5-1",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "exemplar_indices = get_exemplars(X, km, 1)\n",
        "exemplars = lookup_docs(reviews_bow, sum(exemplar_indices, []))\n",
        "for exemplar in exemplars:\n",
        "    print(translate_review(exemplar, reviews_dict))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQfj4WTHPcBe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## AUTOGRADER Step 5.1: Run this to get your score. ##\n",
        "\n",
        "grader.grade(question_id = \"5.1\", answer = exemplar_indices)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "09MuIumNqkyU",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-5-2",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Step 5.2: Prepare and run t-SNE\n",
        "\n",
        "The core idea of t-SNE is preserving the relative distances between all of the data points, but showing those distances in very few dimensions. As such, t-SNE compares every data point against every data point (Cartesian product). For the full dataset, that would be about 19 billion comparisons. So we can't do that.\n",
        "\n",
        "But, fortunately, you have already done a lot of work to cluster these data points. If we take a relatively large number of clusters and only consider 30 or so exemplars from each cluster, that should be small enough for t-SNE. The code below assembles the data subset for t-SNE using functions you have written before. Depending on your implementation this cell could take a long time. You do not need to modify this cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Drw0G08cPV4j",
        "colab": {}
      },
      "source": [
        "exemplar_indices = get_exemplars(X, km, 30)\n",
        "exemplars = lookup_docs(reviews_tfidf, sum(exemplar_indices, []))\n",
        "for_tsne = densify(exemplars, len(reviews_dict))\n",
        "for_tsne.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "nbgrader": {
          "grade": true,
          "grade_id": "visible-test-5-2",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "mrxCt43aLzBp",
        "colab": {}
      },
      "source": [
        "## AUTOGRADER Step 5.2: Run this to get your score. ##\n",
        "\n",
        "grader.grade(question_id = \"5.2\", answer = (for_tsne.shape[0], for_tsne.shape[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DV2O5ITOtRws"
      },
      "source": [
        "The hyperparameters for t-SNE that I used to get a pretty picture are given below. All you need to do is look up the command to train the t-SNE model, which is given in the [API](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html). Call your t-SNE vectors `embeddings_2d`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fb9lWlvaQDKT",
        "nbgrader": {
          "grade": false,
          "grade_id": "answer-5-2",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# answer 5.2\n",
        "# TODO: Run t-SNE\n",
        "tsne_model_2d = TSNE(perplexity=20, n_components=2, init='pca', n_iter=3500, random_state=1911)\n",
        "# TODO #"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XgfDd2btu1f4",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-5-3",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Step 5.3: Color the points\n",
        "\n",
        "Some code to plot the t-SNE vectors is given below, but it won't look very pretty yet because we have not decided on a color scheme for the points. We will implement two options."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x8TBFcnGuzAI",
        "colab": {}
      },
      "source": [
        "def tsne_plot(embedding_clusters, a):\n",
        "    plt.figure(figsize=(16, 9))\n",
        "    colors = cm.rainbow(np.linspace(0, 1, len(embedding_clusters)))\n",
        "    for embeddings, color in zip(embedding_clusters, colors):\n",
        "        x = embeddings[:, 0]\n",
        "        y = embeddings[:, 1]\n",
        "        plt.scatter(x, y, c=[color]*len(x), alpha=a)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kUbdubT3vR2r",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-5-3-1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "#### Step 5.3.1: By cluster membership\n",
        "\n",
        "The most straighforward choice would be to color a point according to the k-means cluster to which it was assigned. k-means is based on Euclidean distance and t-SNE is based on angular distance, so there should be some, but not total, consistency between the two algorithms.\n",
        "\n",
        "`get_exemplars` originally had a list of lists of indices, but these had to be flattened for `lookup_docs`. Therefore, you just need to re-group the points into clusters. There are exactly 30 points in each cluster, so there are many ways to do this. If you want an extra challenge, you can solve this part without using the magic number 30. But it is not required and will not affect your homework score.\n",
        "\n",
        "Call the re-grouped t-SNE vectors `embeddings`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hwjNAgVFySLu",
        "nbgrader": {
          "grade": false,
          "grade_id": "answer-5-3-1",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# answer 5.3.1\n",
        "# TODO: group the t-SNE embeddings by cluster membership\n",
        "embeddings = []\n",
        "# TODO #"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d9iZmqSYvKB_",
        "nbgrader": {
          "grade": true,
          "grade_id": "visible-test-5-3-1",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "tsne_plot(embeddings, 0.7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRSYij6dWoma",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## AUTOGRADER Step 5.3.1: Run this to get your score. ##\n",
        "\n",
        "grader.grade(question_id = \"5.3.1\", answer = str(type(embeddings[0])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "l1beI48Tw-KK",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-5-3-2",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "#### Step 5.3.2 By star rating\n",
        "\n",
        "Now as a finale, group the reviews by star rating. When you are done, `embeddings` should have a length of five. Then, redraw the plot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qs9idX2wySN4",
        "nbgrader": {
          "grade": false,
          "grade_id": "answer-5-3-2",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# answer 5.3.2\n",
        "# TODO: group the t-SNE embeddings by star rating\n",
        "embeddings = [[],[],[],[],[]]\n",
        "# TODO #"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oyDfy4i_QQUa",
        "nbgrader": {
          "grade": true,
          "grade_id": "visible-test-5-3-2",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "tsne_plot(embeddings, 0.7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCdICmYrWenR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## AUTOGRADER Step 5.3.2: Run this to get your score. ##\n",
        "\n",
        "grader.grade(question_id = \"5.3.2\", answer = str(type(embeddings[0])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZbCFAGi_xdlX",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-5-3-3",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "As you can see, the clusters formed by k-means and t-SNE do not seem to correspond to the star ratings. This pretty, but somewhat unhappy standpoint is where Homework 4 ends and your project begins.\n",
        "\n",
        "What kinds of analyses have we not tried? What structure is still hidden in these reviews? Can you infer how these 100,000 reviews were selected? Can something fancier than a random forest have higher accuracy in predicting the star rating?\n",
        "\n",
        "For your project, your task is to put together an interesting notebook about this dataset, similar to this one, the other homework notebooks from this class, or articles on [towardsdatascience.com](https://towardsdatascience.com/). The notebook should explain what you did in such a way that a non-technical person can read it. As such, your project will be manually graded as a work of data science communication. We hope that you can use your project notebook as something that you can show off in data science job interviews and the like. \n",
        "\n",
        "Congratulations on all of your work so far! Five stars for you!"
      ]
    }
  ]
}